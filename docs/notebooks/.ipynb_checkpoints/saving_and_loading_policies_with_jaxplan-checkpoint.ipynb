{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1a32d4",
   "metadata": {},
   "source": [
    "# Saving and loading trained policies in JaxPlan. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df640593",
   "metadata": {},
   "source": [
    "In this notebook, we illustrate the procedure of saving and loading trained JaxPlan policies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29af0af",
   "metadata": {},
   "source": [
    "Start by installing the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ca10951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade pip\n",
    "%pip install --quiet git+https://github.com/pyrddlgym-project/pyRDDLGym.git\n",
    "%pip install --quiet git+https://github.com/pyrddlgym-project/rddlrepository.git\n",
    "%pip install --quiet git+https://github.com/pyrddlgym-project/pyRDDLGym-jax.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee945c7",
   "metadata": {},
   "source": [
    "Import the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06501d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import pickle\n",
    "\n",
    "import pyRDDLGym\n",
    "from pyRDDLGym_jax.core.planner import JaxDeepReactivePolicy, JaxBackpropPlanner, JaxOfflineController, load_config_from_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9ed29c",
   "metadata": {},
   "source": [
    "We will load the Wildfire example to illustrate the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "750dff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = pyRDDLGym.make('Wildfire_MDP_ippc2014', '1', vectorized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2c1b3a",
   "metadata": {},
   "source": [
    "Let's now train a fresh policy network to solve this problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cf99e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    282 it /    -223.691406 train /    -425.093750 test /    -343.765625 best / 0 status: : 282it [00:09, 30.72it/s]   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean': -319.1,\n",
       " 'median': -40.0,\n",
       " 'min': -7525.0,\n",
       " 'max': -35.0,\n",
       " 'std': 1042.2375880767302}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planner = JaxBackpropPlanner(rddl=env.model, plan=JaxDeepReactivePolicy(), optimizer_kwargs={'learning_rate': 0.01})\n",
    "agent = JaxOfflineController(planner, print_summary=False, train_seconds=10)\n",
    "agent.evaluate(env, episodes=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b72d9f2",
   "metadata": {},
   "source": [
    "To save the model, we will just pickle the final parameters of the policy network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6e289af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wildfire_drp.pickle', 'wb') as file:\n",
    "    pickle.dump(agent.params, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49379b37",
   "metadata": {},
   "source": [
    "Now, let's load the pickled parameters and pass them to a newly-instantiated controller:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5ba9d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wildfire_drp.pickle', 'rb') as file:\n",
    "    params = pickle.load(file)\n",
    "    \n",
    "new_planner = JaxBackpropPlanner(rddl=env.model, plan=JaxDeepReactivePolicy())\n",
    "new_agent = JaxOfflineController(new_planner, params=params, print_summary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e308bf",
   "metadata": {},
   "source": [
    "Note that in this case there is no pre-training of the policy. Let's evaluate the agent to make sure it still performs the same as the trained one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c212dce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': -412.9,\n",
       " 'median': -35.0,\n",
       " 'min': -4050.0,\n",
       " 'max': -35.0,\n",
       " 'std': 1089.5086461336598}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_agent.evaluate(env, episodes=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709354d5",
   "metadata": {},
   "source": [
    "Indeed, the performance is quite similar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
